{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icartt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from math import pi\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv file with information about bin locations\n",
    "file_info_file = \"C:/Users/cphal/OneDrive/Desktop/Aerosols/Module A/Metadata/module_a_bins.csv\"\n",
    "binlocations = pd.read_csv(file_info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function purpose: get new file name based on abbreviation saved in the binlocations dataframe\n",
    "#Input:     filename, the name of the file being analyzed\n",
    "#           binlocations, the dataframe containing the information about the bin locations in each file\n",
    "#Returns:   new_file_name, the new file name consistent with our naming conventions\n",
    "def get_new_name(filename, binlocations):\n",
    "    #filename is uppercase\n",
    "    filename = filename.upper()\n",
    "\n",
    "    #find associated row by looping through files\n",
    "    campaign = ''\n",
    "    instrument = ''\n",
    "    i = 0\n",
    "    campaign_found = False\n",
    "    instrument_found = False\n",
    "    while (i < len(binlocations) or (not campaign_found and not instrument_found)):\n",
    "        if (not campaign_found and isinstance(binlocations.iloc[i]['Campaign'],str)):\n",
    "            if(binlocations.iloc[i]['Campaign'] in filename):\n",
    "                campaign = binlocations.iloc[i]['Campaign']\n",
    "                campaign_found = True\n",
    "        if (not instrument_found and isinstance(binlocations.iloc[i]['Filename/Instrument'],str)):\n",
    "            if(binlocations.iloc[i]['Filename/Instrument'] in filename):\n",
    "                instrument = binlocations.iloc[i]['Filename nickname']\n",
    "                instrument_found = True\n",
    "        i += 1\n",
    "\n",
    "    if(not campaign_found or not instrument_found):\n",
    "        print('FATAL ERROR: campaign/instrument not found for ' + filename)\n",
    "        exit(0)\n",
    "    \n",
    "    #find new filename and get its index\n",
    "    new_file_name = campaign + '_' + instrument + '_'\n",
    "\n",
    "    return new_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function Purpose: create diameter dataframe\n",
    "#Returns dfDiam, a dataframe that contains the diameters associated with each instrument for each campaign \n",
    "#and their location in the file headers\n",
    "def createDiamDf():\n",
    "    diameter_file = \"C:/Users/cphal/OneDrive/Desktop/Aerosols/Module A/NASA diameters.csv\"\n",
    "\n",
    "    #diameters_info = pd.read_csv(diameter_file, delimiter=',', encoding='utf-8')\n",
    "    file = open(diameter_file,'r')\n",
    "    count = 0\n",
    "    dfDiam = pd.DataFrame(columns = ['file_name', 'row', 'column_start', 'column_end', 'diameters'], index = range(0,23))\n",
    "\n",
    "    #cycle through file, extract values, and put them where they're supposed to be\n",
    "    for line in file:\n",
    "        if count > 0:\n",
    "            line.strip('/n')\n",
    "            nextline = line.split('[')\n",
    "            nextline[1] = '[' + nextline[1]\n",
    "            firstpart = nextline[0].split(',')\n",
    "\n",
    "            dfDiam.at[count-1, 'file_name'] = firstpart[0]\n",
    "            dfDiam.at[count-1, 'row'] = firstpart[1]\n",
    "            dfDiam.at[count-1, 'column_start'] = firstpart[2]\n",
    "            dfDiam.at[count-1, 'column_end'] = firstpart[3]\n",
    "            dfDiam.at[count-1, 'diameters'] = nextline[1]\n",
    "        count += 1\n",
    "\n",
    "    return dfDiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function purpose: find index of the nearest value of the input value in array\n",
    "#Input:     array, a numpy array containing the instrument measured diameters\n",
    "#           value, the value we are trying to find the nearest value of\n",
    "#Returns:   idx, the index of the nearest value to value in array\n",
    "def find_nearest(array, value):\n",
    "    n = [abs(i-value) for i in array]\n",
    "    idx = n.index(min(n))\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function purpose: Rebin number distributions based on user-defined partitions and calculate volume distribution\n",
    "#Input:     filename, the name of the file to be analyzed\n",
    "#           dfDiam, the dataframe containing information about the diameters for each instrument\n",
    "#Returns:   file_M_1, the dataframe containing the values calculated in the module\n",
    "#NOTE: This could probably be split into more methods for readibility (don't tell my software instructors what this looks like)\n",
    "def module_a(filename, dfDiam):\n",
    "        \n",
    "    new_file_name = get_new_name(filename, binlocations)\n",
    "\n",
    "    #get info from dfDiam\n",
    "    ind = dfDiam.index[dfDiam['file_name'] == new_file_name].tolist()\n",
    "\n",
    "    if (len(ind) > 1):\n",
    "        print('FATAL ERROR: more than 1 match for ' + new_file_name)\n",
    "        exit(0)\n",
    "\n",
    "    #format diameter input properly\n",
    "    diameters = dfDiam.at[ind[0],'diameters']\n",
    "    diameters = diameters.strip('][\\n').split(',')\n",
    "    diameters = [float(x) for x in diameters]\n",
    "    size_dist_diameter_input = pd.Series(diameters)\n",
    "\n",
    "    #load in ict file to python\n",
    "    ict = icartt.Dataset(filename)\n",
    "    df = ict.data[:]\n",
    "    df = pd.DataFrame(df)\n",
    "    varnames = [x for x in ict.variables]\n",
    "\n",
    "    #find the actual columns we want based on dfDiam\n",
    "    column_start = int(dfDiam.at[ind[0],'column_start'])\n",
    "    column_end = int(dfDiam.at[ind[0],'column_end'])\n",
    "    binnames = varnames[column_start:column_end]\n",
    "    size_dist_input_original = df[binnames]\n",
    "\n",
    "    #transpose size_dist_input to get it to work with Module A (not sure why but this was how original code was written)\n",
    "    size_dist_input = pd.DataFrame.transpose(size_dist_input_original)\n",
    "    ser=pd.Series(range(np.size(size_dist_input,1)))\n",
    "    size_dist_input.rename(columns = ser, inplace = True)\n",
    "\n",
    "    #replace all input values less than 0 with np.nan\n",
    "    #FIXME: consider LLOD of instrument instead instead of 0\n",
    "    size_dist_input.mask(size_dist_input <= 0, np.nan , inplace=True )\n",
    "\n",
    "    #create list to hold input values\n",
    "    d_Nx_list = [6, 12]\n",
    "    d_Vx_list = [36,144]\n",
    "    bin_num = 3\n",
    "\n",
    "    #NOTE: can modify this to be user defined but I found it easier to harcode the input values\n",
    "    #Also I think I accidentally deleted this method because I wasn't using it\n",
    "    #get_inputs(d_Nx_list, d_Vx_list)\n",
    "\n",
    "    #reformat date and time\n",
    "    #TODO: separate date and times for \"atomic\" values (for databse design\n",
    "    date_time = ict.times\n",
    "    datetimedf = pd.DataFrame(date_time, columns= ['datetime'])\n",
    "    date = str(date_time[0])\n",
    "    date = datetime.datetime.strptime(date, '%Y-%m-%dT%H:%M:%S.%f000').strftime('%Y_%m_%d')\n",
    "\n",
    "    #make sure properly formatted\n",
    "    size_dist_diameter_input.reset_index(drop=True)\n",
    "    size_dist_diameter_input = size_dist_diameter_input.astype(float)\n",
    "\n",
    "    #calculate volume distribution based on diameter^3\n",
    "    diameter_power = np.power(size_dist_diameter_input, 3)\n",
    "    diameter_power = diameter_power.to_numpy()\n",
    "    size_dist_volume = pi/6*size_dist_input.mul(diameter_power,axis='index')\n",
    "\n",
    "    #calculate dVdlogdP using dNdlogdP NOTE: ORIGINAL CODE. IS SUPER SLOW\n",
    "    #size_dist_volume_slow = pd.DataFrame().reindex_like(size_dist_input)\n",
    "    #for m in range(np.size(size_dist_volume_slow,1)):\n",
    "    #for n in range(len(size_dist_diameter_input)):\n",
    "    #size_dist_volume_slow.values[n,m]=pi/6* np.power(size_dist_diameter_input, 3).values[n]*size_dist_input.values[n,m]\n",
    "\n",
    "    #prepare for trapz calculation\n",
    "    size_dist_input[np.isnan(size_dist_input)] = 0 \n",
    "    size_dist_volume[np.isnan(size_dist_volume)] = 0 \n",
    "    ln_size_dist_diameter_input=np.log(size_dist_diameter_input)\n",
    "\n",
    "    #NOTE: MODIFIED CODE\n",
    "    #instead of having [num_bins] separate arrays with equal length, have [num_bins] columns in a dataframe\n",
    "    #have a row for each data type needed to store an array in multidimensional array!\n",
    "\n",
    "    #find nearest index in size_dist_diameter_input\n",
    "    d_Nx_nearest = []\n",
    "    d_Vx_nearest = []\n",
    "\n",
    "    #for num_bins, find nearest index in size_dist_diameter input\n",
    "    for i in range(len(d_Nx_list)):\n",
    "        x = find_nearest(size_dist_diameter_input, d_Nx_list[i])\n",
    "        d_Nx_nearest.append(x)\n",
    "    for i in range(len(d_Vx_list)):\n",
    "        x = find_nearest(size_dist_diameter_input, d_Vx_list[i])\n",
    "        d_Vx_nearest.append(x)\n",
    "\n",
    "    #create empty dataframes to hold num_bins: should be (num_bins) x (num_columns in size_dist)\n",
    "    num_bins = len(d_Nx_list) + 1\n",
    "    N_df = pd.DataFrame(index = range(np.size(size_dist_input,1)), columns = range(num_bins))\n",
    "    F_N_df = pd.DataFrame(index = range(np.size(size_dist_input,1)), columns = range(num_bins))\n",
    "    V_df = pd.DataFrame(index = range(np.size(size_dist_input,1)), columns = range(num_bins))\n",
    "    F_V_df = pd.DataFrame(index = range(np.size(size_dist_input,1)), columns = range(num_bins))\n",
    "\n",
    "    #add beginning and ending indexes for the divisions\n",
    "    d_Nx_nearest.insert(0,0)\n",
    "    d_Nx_nearest.append(len(size_dist_diameter_input))\n",
    "    d_Vx_nearest.insert(0,0)\n",
    "    d_Vx_nearest.append(len(size_dist_diameter_input))\n",
    "\n",
    "    #for each bin, make a smaller dataframe with the diameter bins desired. Then apply trapz calculation by row\n",
    "    #and add result to dataframe in adjacent bin\n",
    "    for i in range(num_bins):\n",
    "        if i == 0: \n",
    "            small_df = size_dist_input.iloc[0:(d_Nx_nearest[i+1]),:]\n",
    "            N_df.iloc[:,i] = np.trapz(small_df, x=ln_size_dist_diameter_input[0:(d_Nx_nearest[i+1])], axis=0)\n",
    "        elif i > 0:\n",
    "            small_df = size_dist_input.iloc[(d_Nx_nearest[i]+1):(d_Nx_nearest[i+1]),:]\n",
    "            N_df.iloc[:,i] = np.trapz(small_df, x=ln_size_dist_diameter_input[(d_Nx_nearest[i]+1):(d_Nx_nearest[i+1])], axis=0)\n",
    "    for i in range(num_bins):\n",
    "        if i == 0: \n",
    "            small_df = size_dist_volume.iloc[0:(d_Vx_nearest[i+1]),:]\n",
    "            V_df.iloc[:,i] = np.trapz(small_df, x=ln_size_dist_diameter_input[0:(d_Vx_nearest[i+1])], axis=0)\n",
    "        elif i > 0:\n",
    "            small_df = size_dist_volume.iloc[(d_Vx_nearest[i]+1):(d_Vx_nearest[i+1]),:]\n",
    "            V_df.iloc[:,i] = np.trapz(small_df, x=ln_size_dist_diameter_input[(d_Vx_nearest[i]+1):(d_Vx_nearest[i+1])], axis=0)\n",
    "\n",
    "    #calculate areaXY_number and volumeXY_number\n",
    "    areaXY_number = pd.Series(np.trapz(size_dist_input, x=ln_size_dist_diameter_input, axis=0))\n",
    "    volumeXY_number = pd.Series(np.trapz(size_dist_volume, x=ln_size_dist_diameter_input, axis=0))\n",
    "\n",
    "    #FIXME: question: can we replace 0 with np.nan?\n",
    "    areaXY_number.replace(0, np.nan, inplace=True)\n",
    "    volumeXY_number.replace(0, np.nan, inplace=True)\n",
    "    print(volumeXY_number.head())\n",
    "\n",
    "    #divide N by areaXY for f_N dataframe\n",
    "    for i in range(num_bins):\n",
    "        F_N_df.iloc[:,i] = N_df.iloc[:,i] / areaXY_number\n",
    "    for i in range(num_bins):\n",
    "        F_V_df.iloc[:,i] = V_df.iloc[:,i] / volumeXY_number\n",
    "\n",
    "    #put in big dataframe!\n",
    "    file_M_1 = pd.DataFrame() \n",
    "    file_M_1['datetime'] = datetimedf\n",
    "    for i in range(num_bins):\n",
    "        file_M_1['N'+str(i+1)] = N_df.iloc[:,i]\n",
    "        file_M_1['F_N'+str(i+1)] = F_N_df.iloc[:,i]\n",
    "        file_M_1['V'+str(i+1)] = V_df.iloc[:,i]\n",
    "        file_M_1['F_V'+str(i+1)] = F_V_df.iloc[:,i]\n",
    "    file_M_1['V_total'] = volumeXY_number\n",
    "    file_M_1['N_total'] = areaXY_number\n",
    "\n",
    "    #export csv\n",
    "    filepath = 'C:/Users/cphal/OneDrive/Desktop/Aerosols/Module A/Module_A_out/'\n",
    "    export_csv = file_M_1.to_csv(filepath+new_file_name+date+'.csv', index = None, header=True) \n",
    "    return(file_M_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN METHOD: FOR A SINGLE FILE\n",
    "filebeginning = \"C:/Users/cphal/OneDrive/Desktop/Aerosols/Module A/Success/\"\n",
    "filename = filebeginning + 'ACTIVATE-LARGE-SMPS_HU25_20220618_R1.ict'\n",
    "dfDiam = createDiamDf()\n",
    "\n",
    "#calculate file\n",
    "file_M_1 = module_a(filename,dfDiam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN METHOD: FOR LOOPING FILES\n",
    "#set directory\n",
    "fileDirectory = str('C:/Users/cphal/OneDrive/Desktop/Aerosols/Module A/Failure_Bin_Loc/')\n",
    "\n",
    "dfDiam = createDiamDf()\n",
    "\n",
    "#get filenames in folder\n",
    "path = os.chdir(fileDirectory)\n",
    "with os.scandir(path) as entries:\n",
    "    for entry in entries:\n",
    "        filename = fileDirectory + entry.name\n",
    "        print('Processing ' + entry.name)\n",
    "        module_a(filename, dfDiam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
